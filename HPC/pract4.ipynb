{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile vect_add.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void addVectors(int* A, int* B, int* C, int n)\n",
        "{\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n)\n",
        "    {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int n = 1000000;\n",
        "    int* A, * B, * C;\n",
        "    int size = n * sizeof(int);\n",
        "\n",
        "    // Allocate memory on the host\n",
        "    cudaMallocHost(&A, size);\n",
        "    cudaMallocHost(&B, size);\n",
        "    cudaMallocHost(&C, size);\n",
        "\n",
        "    // Initialize the vectors\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        A[i] = i;\n",
        "        B[i] = i * 2;\n",
        "    }\n",
        "    // Allocate memory on the device\n",
        "    int* dev_A, * dev_B, * dev_C;\n",
        "    cudaMalloc(&dev_A, size);\n",
        "    cudaMalloc(&dev_B, size);\n",
        "    cudaMalloc(&dev_C, size);\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch the kernel\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (n + blockSize - 1) / blockSize;\n",
        "    addVectors<<<numBlocks, blockSize>>>(dev_A, dev_B, dev_C, n);\n",
        "\n",
        "    // Copy data from device to host\n",
        "    cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the results\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        cout << C[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(dev_A);\n",
        "    cudaFree(dev_B);\n",
        "    cudaFree(dev_C);\n",
        "    cudaFreeHost(A);\n",
        "    cudaFreeHost(B);\n",
        "    cudaFreeHost(C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snDpQKbqptQ8",
        "outputId": "dace491d-ad0d-4f9c-97b0-684083a92d56"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vect_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vect_add.cu -o output"
      ],
      "metadata": {
        "id": "qlGjtZeFo5cQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z95AyUARpas8",
        "outputId": "f3b58f7a-4b67-467a-b6c6-182fcef2547c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 3 6 9 12 15 18 21 24 27 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c6ZrfW6tp-5W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}